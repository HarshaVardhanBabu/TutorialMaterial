{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imputation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshaVardhanBabu/TutorialMaterial/blob/master/Imputation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqr5g1_z7tsl",
        "colab_type": "code",
        "outputId": "c1e4e89e-c745-44fe-84ac-66ea92ed726d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler\n",
        "from sklearn.datasets import load_boston\n",
        "import numpy as np\n",
        "# https://pypi.org/project/fancyimpute/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyefxJeo6Bkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "print(boston.data.shape)\n",
        "X = boston.data\n",
        "Y = boston.target\n",
        "\n",
        "X = X.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHgjOqRT7BqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.ravel()[np.random.choice(X.size, 100, replace=False)] = np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvp9I07J7we0",
        "colab_type": "code",
        "outputId": "961d0fbc-c889-46b3-9a88-67c5ff30a74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_filled_knn = KNN(k=3).fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imputing row 1/506 with 1 missing, elapsed time: 0.050\n",
            "Imputing row 101/506 with 0 missing, elapsed time: 0.051\n",
            "Imputing row 201/506 with 0 missing, elapsed time: 0.052\n",
            "Imputing row 301/506 with 1 missing, elapsed time: 0.053\n",
            "Imputing row 401/506 with 0 missing, elapsed time: 0.053\n",
            "Imputing row 501/506 with 0 missing, elapsed time: 0.054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmSFCzcT8me1",
        "colab_type": "code",
        "outputId": "571fd0b8-ec27-434a-f46e-3a1382e50425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# matrix completion using convex optimization to find low-rank solution\n",
        "# that still matches observed values. Slow!\n",
        "X_filled_nnm = NuclearNormMinimization().fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------\n",
            "\tSCS v2.1.1 - Splitting Conic Solver\n",
            "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
            "----------------------------------------------------------------------------\n",
            "Lin-sys: sparse-direct, nnz in A = 180786\n",
            "eps = 1.00e-04, alpha = 1.50, max_iters = 50000, normalize = 1, scale = 1.00\n",
            "acceleration_lookback = 10, rho_x = 1.00e-03\n",
            "Variables n = 148096, constraints m = 161252\n",
            "Cones:\tprimal zero / dual free vars: 6578\n",
            "\tlinear vars: 19734\n",
            "\tsd vars: 134940, sd blks: 1\n",
            "Setup time: 2.35e-01s\n",
            "----------------------------------------------------------------------------\n",
            " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
            "----------------------------------------------------------------------------\n",
            "     0| 5.20e+21  4.89e+21  1.00e+00 -7.99e+26  1.45e+26  1.96e+26  1.24e-01 \n",
            "   100| 7.62e-04  8.19e-04  2.78e-04  1.75e+04  1.75e+04  1.82e-12  2.94e+01 \n",
            "   200| 6.85e-04  6.88e-04  1.57e-04  1.75e+04  1.75e+04  7.01e-12  5.86e+01 \n",
            "   300| 1.34e-05  1.10e-05  1.03e-05  1.75e+04  1.75e+04  5.93e-12  8.77e+01 \n",
            "----------------------------------------------------------------------------\n",
            "Status: Solved\n",
            "Timing: Solve time: 8.77e+01s\n",
            "\tLin-sys: nnz in L factor: 496612, avg solve time: 3.53e-03s\n",
            "\tCones: avg projection time: 2.36e-01s\n",
            "\tAcceleration: avg step time: 4.28e-02s\n",
            "----------------------------------------------------------------------------\n",
            "Error metrics:\n",
            "dist(s, K) = 4.9153e-08, dist(y, K*) = 1.6004e-09, s'y/|s||y| = 9.4772e-14\n",
            "primal res: |Ax + s - b|_2 / (1 + |b|_2) = 1.3391e-05\n",
            "dual res:   |A'y + c|_2 / (1 + |c|_2) = 1.0960e-05\n",
            "rel gap:    |c'x + b'y| / (1 + |c'x| + |b'y|) = 1.0309e-05\n",
            "----------------------------------------------------------------------------\n",
            "c'x = 17507.4229, -b'y = 17507.0620\n",
            "============================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGghwpJ48uRn",
        "colab_type": "code",
        "outputId": "84be0073-ed72-4e90-dc6d-def35bf80a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Instead of solving the nuclear norm objective directly, instead\n",
        "# induce sparsity using singular value thresholding\n",
        "X_incomplete_normalized = BiScaler().fit_transform(X)\n",
        "X_filled_softimpute = SoftImpute().fit_transform(X_incomplete_normalized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[BiScaler] Initial log residual value = 14.884686\n",
            "[BiScaler] Iter 1: log residual = 3.166649, log improvement ratio=11.718036\n",
            "[BiScaler] Iter 2: log residual = 2.470413, log improvement ratio=0.696237\n",
            "[BiScaler] Iter 3: log residual = 1.792303, log improvement ratio=0.678110\n",
            "[BiScaler] Iter 4: log residual = 1.150422, log improvement ratio=0.641881\n",
            "[BiScaler] Iter 5: log residual = 0.510987, log improvement ratio=0.639435\n",
            "[BiScaler] Iter 6: log residual = -0.133191, log improvement ratio=0.644178\n",
            "[BiScaler] Iter 7: log residual = -0.786211, log improvement ratio=0.653020\n",
            "[BiScaler] Iter 8: log residual = -1.448650, log improvement ratio=0.662439\n",
            "[BiScaler] Iter 9: log residual = -2.119371, log improvement ratio=0.670721\n",
            "[BiScaler] Iter 10: log residual = -2.796614, log improvement ratio=0.677243\n",
            "[BiScaler] Iter 11: log residual = -3.478584, log improvement ratio=0.681971\n",
            "[BiScaler] Iter 12: log residual = -4.163702, log improvement ratio=0.685117\n",
            "[BiScaler] Iter 13: log residual = -4.850680, log improvement ratio=0.686978\n",
            "[BiScaler] Iter 14: log residual = -5.538529, log improvement ratio=0.687850\n",
            "[BiScaler] Iter 15: log residual = -6.226525, log improvement ratio=0.687996\n",
            "[BiScaler] Iter 16: log residual = -6.914161, log improvement ratio=0.687636\n",
            "[BiScaler] Iter 17: log residual = -7.601108, log improvement ratio=0.686947\n",
            "[BiScaler] Iter 18: log residual = -8.287169, log improvement ratio=0.686061\n",
            "[BiScaler] Iter 19: log residual = -8.972250, log improvement ratio=0.685081\n",
            "[BiScaler] Iter 20: log residual = -9.656330, log improvement ratio=0.684079\n",
            "[BiScaler] Iter 21: log residual = -10.339436, log improvement ratio=0.683106\n",
            "[BiScaler] Iter 22: log residual = -11.021631, log improvement ratio=0.682195\n",
            "[BiScaler] Iter 23: log residual = -11.702998, log improvement ratio=0.681367\n",
            "[BiScaler] Iter 24: log residual = -12.383631, log improvement ratio=0.680634\n",
            "[BiScaler] Iter 25: log residual = -13.063630, log improvement ratio=0.679999\n",
            "[BiScaler] Iter 26: log residual = -13.743092, log improvement ratio=0.679462\n",
            "[BiScaler] Iter 27: log residual = -14.422112, log improvement ratio=0.679020\n",
            "[BiScaler] Iter 28: log residual = -15.100778, log improvement ratio=0.678666\n",
            "[BiScaler] Iter 29: log residual = -15.779173, log improvement ratio=0.678395\n",
            "[BiScaler] Iter 30: log residual = -16.457372, log improvement ratio=0.678199\n",
            "[BiScaler] Iter 31: log residual = -17.135442, log improvement ratio=0.678070\n",
            "[BiScaler] Iter 32: log residual = -17.813443, log improvement ratio=0.678001\n",
            "[BiScaler] Iter 33: log residual = -18.491427, log improvement ratio=0.677984\n",
            "[BiScaler] Iter 34: log residual = -19.169441, log improvement ratio=0.678014\n",
            "[BiScaler] Iter 35: log residual = -19.847525, log improvement ratio=0.678084\n",
            "[BiScaler] Iter 36: log residual = -20.525713, log improvement ratio=0.678188\n",
            "[BiScaler] Iter 37: log residual = -21.204035, log improvement ratio=0.678322\n",
            "[BiScaler] Iter 38: log residual = -21.882515, log improvement ratio=0.678481\n",
            "[BiScaler] Iter 39: log residual = -22.561175, log improvement ratio=0.678660\n",
            "[BiScaler] Iter 40: log residual = -23.240032, log improvement ratio=0.678857\n",
            "[BiScaler] Iter 41: log residual = -23.919100, log improvement ratio=0.679068\n",
            "[BiScaler] Iter 42: log residual = -24.598390, log improvement ratio=0.679290\n",
            "[BiScaler] Iter 43: log residual = -25.277911, log improvement ratio=0.679521\n",
            "[BiScaler] Iter 44: log residual = -25.957669, log improvement ratio=0.679758\n",
            "[BiScaler] Iter 45: log residual = -26.637669, log improvement ratio=0.680000\n",
            "[BiScaler] Iter 46: log residual = -27.317914, log improvement ratio=0.680245\n",
            "[BiScaler] Iter 47: log residual = -27.998407, log improvement ratio=0.680492\n",
            "[BiScaler] Iter 48: log residual = -28.679147, log improvement ratio=0.680740\n",
            "[BiScaler] Iter 49: log residual = -29.360133, log improvement ratio=0.680987\n",
            "[BiScaler] Iter 50: log residual = -30.041365, log improvement ratio=0.681232\n",
            "[BiScaler] Iter 51: log residual = -30.722840, log improvement ratio=0.681475\n",
            "[BiScaler] Iter 52: log residual = -31.404555, log improvement ratio=0.681715\n",
            "[BiScaler] Iter 53: log residual = -32.086506, log improvement ratio=0.681951\n",
            "[BiScaler] Iter 54: log residual = -32.768691, log improvement ratio=0.682185\n",
            "[BiScaler] Iter 55: log residual = -33.451103, log improvement ratio=0.682413\n",
            "[BiScaler] Iter 56: log residual = -34.133740, log improvement ratio=0.682636\n",
            "[BiScaler] Iter 57: log residual = -34.816596, log improvement ratio=0.682856\n",
            "[BiScaler] Iter 58: log residual = -35.499666, log improvement ratio=0.683070\n",
            "[BiScaler] Iter 59: log residual = -36.182946, log improvement ratio=0.683280\n",
            "[BiScaler] Iter 60: log residual = -36.866429, log improvement ratio=0.683483\n",
            "[BiScaler] Iter 61: log residual = -37.550111, log improvement ratio=0.683683\n",
            "[BiScaler] Iter 62: log residual = -38.233986, log improvement ratio=0.683874\n",
            "[BiScaler] Iter 63: log residual = -38.918048, log improvement ratio=0.684063\n",
            "[BiScaler] Iter 64: log residual = -39.602294, log improvement ratio=0.684245\n",
            "[BiScaler] Iter 65: log residual = -40.286712, log improvement ratio=0.684418\n",
            "[BiScaler] Iter 66: log residual = -40.971323, log improvement ratio=0.684611\n",
            "[BiScaler] Iter 67: log residual = -41.656069, log improvement ratio=0.684746\n",
            "[BiScaler] Iter 68: log residual = -42.341002, log improvement ratio=0.684933\n",
            "[BiScaler] Iter 69: log residual = -43.026078, log improvement ratio=0.685076\n",
            "[BiScaler] Iter 70: log residual = -43.711341, log improvement ratio=0.685263\n",
            "[BiScaler] Iter 71: log residual = -44.396633, log improvement ratio=0.685292\n",
            "[BiScaler] Iter 72: log residual = -45.082191, log improvement ratio=0.685558\n",
            "[BiScaler] Iter 73: log residual = -45.767951, log improvement ratio=0.685760\n",
            "[BiScaler] Iter 74: log residual = -46.453731, log improvement ratio=0.685779\n",
            "[BiScaler] Iter 75: log residual = -47.139918, log improvement ratio=0.686188\n",
            "[BiScaler] Iter 76: log residual = -47.825221, log improvement ratio=0.685303\n",
            "[BiScaler] Iter 77: log residual = -48.511584, log improvement ratio=0.686363\n",
            "[BiScaler] Iter 78: log residual = -49.198923, log improvement ratio=0.687340\n",
            "[BiScaler] Iter 79: log residual = -49.884836, log improvement ratio=0.685912\n",
            "[BiScaler] Iter 80: log residual = -50.570782, log improvement ratio=0.685947\n",
            "[BiScaler] Iter 81: log residual = -51.255578, log improvement ratio=0.684796\n",
            "[BiScaler] Iter 82: log residual = -51.946744, log improvement ratio=0.691166\n",
            "[BiScaler] Iter 83: log residual = -52.630441, log improvement ratio=0.683697\n",
            "[BiScaler] Iter 84: log residual = -53.317104, log improvement ratio=0.686663\n",
            "[BiScaler] Iter 85: log residual = -53.998826, log improvement ratio=0.681722\n",
            "[BiScaler] Iter 86: log residual = -54.684089, log improvement ratio=0.685263\n",
            "[BiScaler] Iter 87: log residual = -55.385022, log improvement ratio=0.700933\n",
            "[BiScaler] Iter 88: log residual = -56.067235, log improvement ratio=0.682212\n",
            "[BiScaler] Iter 89: log residual = -56.764966, log improvement ratio=0.697731\n",
            "[BiScaler] Iter 90: log residual = -57.424477, log improvement ratio=0.659511\n",
            "[BiScaler] Iter 91: log residual = -58.140681, log improvement ratio=0.716204\n",
            "[BiScaler] Iter 92: log residual = -58.776236, log improvement ratio=0.635555\n",
            "[BiScaler] Iter 93: log residual = -59.558390, log improvement ratio=0.782155\n",
            "[BiScaler] Iter 94: log residual = -60.039772, log improvement ratio=0.481382\n",
            "[BiScaler] Iter 95: log residual = -60.918828, log improvement ratio=0.879056\n",
            "[BiScaler] Iter 96: log residual = -61.628517, log improvement ratio=0.709689\n",
            "[BiScaler] Iter 97: log residual = -62.097738, log improvement ratio=0.469221\n",
            "[BiScaler] Iter 98: log residual = -62.619264, log improvement ratio=0.521526\n",
            "[BiScaler] Iter 99: log residual = -63.256521, log improvement ratio=0.637257\n",
            "[BiScaler] Iter 100: log residual = -63.836572, log improvement ratio=0.580051\n",
            "[SoftImpute] Max Singular Value of X_init = 50.840363\n",
            "[SoftImpute] Iter 1: observed MAE=0.031991 rank=12\n",
            "[SoftImpute] Iter 2: observed MAE=0.032029 rank=12\n",
            "[SoftImpute] Iter 3: observed MAE=0.032083 rank=12\n",
            "[SoftImpute] Iter 4: observed MAE=0.032155 rank=12\n",
            "[SoftImpute] Iter 5: observed MAE=0.032228 rank=12\n",
            "[SoftImpute] Iter 6: observed MAE=0.032301 rank=12\n",
            "[SoftImpute] Iter 7: observed MAE=0.032371 rank=12\n",
            "[SoftImpute] Iter 8: observed MAE=0.032432 rank=12\n",
            "[SoftImpute] Iter 9: observed MAE=0.032487 rank=12\n",
            "[SoftImpute] Iter 10: observed MAE=0.032537 rank=12\n",
            "[SoftImpute] Iter 11: observed MAE=0.032581 rank=12\n",
            "[SoftImpute] Iter 12: observed MAE=0.032620 rank=12\n",
            "[SoftImpute] Iter 13: observed MAE=0.032655 rank=12\n",
            "[SoftImpute] Iter 14: observed MAE=0.032685 rank=12\n",
            "[SoftImpute] Iter 15: observed MAE=0.032710 rank=12\n",
            "[SoftImpute] Iter 16: observed MAE=0.032732 rank=12\n",
            "[SoftImpute] Iter 17: observed MAE=0.032751 rank=12\n",
            "[SoftImpute] Iter 18: observed MAE=0.032768 rank=12\n",
            "[SoftImpute] Iter 19: observed MAE=0.032782 rank=12\n",
            "[SoftImpute] Iter 20: observed MAE=0.032794 rank=12\n",
            "[SoftImpute] Iter 21: observed MAE=0.032805 rank=12\n",
            "[SoftImpute] Iter 22: observed MAE=0.032814 rank=12\n",
            "[SoftImpute] Iter 23: observed MAE=0.032822 rank=12\n",
            "[SoftImpute] Iter 24: observed MAE=0.032829 rank=12\n",
            "[SoftImpute] Iter 25: observed MAE=0.032835 rank=12\n",
            "[SoftImpute] Iter 26: observed MAE=0.032840 rank=12\n",
            "[SoftImpute] Iter 27: observed MAE=0.032844 rank=12\n",
            "[SoftImpute] Iter 28: observed MAE=0.032848 rank=12\n",
            "[SoftImpute] Iter 29: observed MAE=0.032851 rank=12\n",
            "[SoftImpute] Iter 30: observed MAE=0.032854 rank=12\n",
            "[SoftImpute] Iter 31: observed MAE=0.032857 rank=12\n",
            "[SoftImpute] Iter 32: observed MAE=0.032859 rank=12\n",
            "[SoftImpute] Iter 33: observed MAE=0.032860 rank=12\n",
            "[SoftImpute] Iter 34: observed MAE=0.032862 rank=12\n",
            "[SoftImpute] Iter 35: observed MAE=0.032863 rank=12\n",
            "[SoftImpute] Iter 36: observed MAE=0.032864 rank=12\n",
            "[SoftImpute] Iter 37: observed MAE=0.032865 rank=12\n",
            "[SoftImpute] Iter 38: observed MAE=0.032866 rank=12\n",
            "[SoftImpute] Iter 39: observed MAE=0.032867 rank=12\n",
            "[SoftImpute] Iter 40: observed MAE=0.032868 rank=12\n",
            "[SoftImpute] Iter 41: observed MAE=0.032868 rank=12\n",
            "[SoftImpute] Iter 42: observed MAE=0.032869 rank=12\n",
            "[SoftImpute] Iter 43: observed MAE=0.032869 rank=12\n",
            "[SoftImpute] Iter 44: observed MAE=0.032869 rank=12\n",
            "[SoftImpute] Iter 45: observed MAE=0.032870 rank=12\n",
            "[SoftImpute] Iter 46: observed MAE=0.032870 rank=12\n",
            "[SoftImpute] Iter 47: observed MAE=0.032870 rank=12\n",
            "[SoftImpute] Iter 48: observed MAE=0.032870 rank=12\n",
            "[SoftImpute] Iter 49: observed MAE=0.032871 rank=12\n",
            "[SoftImpute] Stopped after iteration 49 for lambda=1.016807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fyQfnot9ap0",
        "colab_type": "code",
        "outputId": "7a0a007b-edb4-4bd3-ee9e-fdd046a54439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "missing_mask = ~np.isnan(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ True,  True,  True, ...,  True,  True, False],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]]),\n",
              " array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "                nan],\n",
              "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "         9.1400e+00],\n",
              "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "         4.0300e+00],\n",
              "        ...,\n",
              "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         5.6400e+00],\n",
              "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "         6.4800e+00],\n",
              "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         7.8800e+00]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VavDDGex881V",
        "colab_type": "code",
        "outputId": "b7991f17-932a-4f17-a4b3-349c39abeb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# print mean squared error for the  imputation methods above\n",
        "nnm_mse = ((X_filled_nnm[missing_mask] - X[missing_mask]) ** 2).mean()\n",
        "print(\"Nuclear norm minimization MSE: %f\" % nnm_mse)\n",
        "\n",
        "softImpute_mse = ((X_filled_softimpute[missing_mask] - X[missing_mask]) ** 2).mean()\n",
        "print(\"SoftImpute MSE: %f\" % softImpute_mse)\n",
        "\n",
        "knn_mse = ((X_filled_knn[missing_mask] - X[missing_mask]) ** 2).mean()\n",
        "print(\"knnImpute MSE: %f\" % knn_mse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nuclear norm minimization MSE: 0.000000\n",
            "SoftImpute MSE: 25663.819201\n",
            "knnImpute MSE: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrLI1HGU9q03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}